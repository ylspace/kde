From patchwork Thu Apr  4 20:23:43 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Barret Rhoden <brho@google.com>
X-Patchwork-Id: 10886259
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 97879922
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:08 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 826A828AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:08 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 76BC428AF2; Thu,  4 Apr 2019 20:24:08 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-15.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI,
	USER_IN_DEF_DKIM_WL autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 020D728AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:08 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730835AbfDDUYG (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 4 Apr 2019 16:24:06 -0400
Received: from mail-qk1-f201.google.com ([209.85.222.201]:54963 "EHLO
        mail-qk1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1729433AbfDDUYF (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 4 Apr 2019 16:24:05 -0400
Received: by mail-qk1-f201.google.com with SMTP id v2so3148231qkf.21
        for <kvm@vger.kernel.org>; Thu, 04 Apr 2019 13:24:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=bQ0sQyIId1gc5GI/6sG0i+XMj4HgpGtF7leH+EhLTRc=;
        b=ijTFYlRoW4d47hWxBRHQLu/ateNtiTcTZ+8xQ0HbOLuEwCH9dLLlDdCkYuyztCMp2o
         mXNiyTtABt6twjeB+s9nV2Kdw8ly+2WDriO4gnJLLcnKCqFMxb5ga5GT1835KhFx8SnY
         7qa/VMYbhRGXltNIg9YdtfqW4UaIs2gyv2C3qVSjTb0YTPr3kFtkrLulCjYuPj8L9Lfx
         Lht/51UA74SPfHmlvFZmQwVHKnwA7GBODxFpS4EfsmMiyDj7+oajwvNvXRGvJaMq+oSA
         tmn6M7u/c3vwhUIHuMggwT1WToIBTF4OXiUJ1xYG+jbhchiANICU0GXr5ku6Fyt+6048
         cXUg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=bQ0sQyIId1gc5GI/6sG0i+XMj4HgpGtF7leH+EhLTRc=;
        b=qiUdjLGWJcpg1NdTFl2GgQU3nkK0vibTz72/9cUQTDz35LVWA0Hgw7Xq1aerp1vgXJ
         +5Ii1OKPfK9ddapctro1pYJC9E6+DWAdSwHSBQZhflr7SIQBq2DV5wqXVZ94ySKUUX9t
         xOgrptnwHBdOEVVQpUpxS2h3M+X6g58R3LOcn3/V2IA66wh0ZZDVZYtsGwZcHOBqbKmK
         27QUi+2JxAU637s8Y8wyK3WeD18rM9U2mGQwpG8Mpu9aakP7RDXjmVOuukxmaSYWg4hK
         sf5u1jYlsXDGT4hdrK45LcDwua5ZVXLcQg07QI3DaQYOLI+9G6+EmL37mG7UHuhT+MQU
         +TLQ==
X-Gm-Message-State: APjAAAVAokYpLCkd7Ofet7ZFRWEyGgWaC12a/zmacid3XC6U1YVPc5jB
        +9rlpLOv5FcUa/m+nWlCJTT6Y6yW
X-Google-Smtp-Source: 
 APXvYqweExkGubWO86xzjg+OVs3wkuGafcUO9nmeR10fv77Ltl1p85rnr+gCrj0y4oMZjzw64K7LVGog
X-Received: by 2002:ac8:2e7a:: with SMTP id s55mr1261618qta.34.1554409444323;
 Thu, 04 Apr 2019 13:24:04 -0700 (PDT)
Date: Thu,  4 Apr 2019 16:23:43 -0400
In-Reply-To: <20190404202345.133553-1-brho@google.com>
Message-Id: <20190404202345.133553-2-brho@google.com>
Mime-Version: 1.0
References: <20190404202345.133553-1-brho@google.com>
X-Mailer: git-send-email 2.21.0.392.gf8f6787159e-goog
Subject: [PATCH v3 1/3] mm: make dev_pagemap_mapping_shift() externally
 visible
From: Barret Rhoden <brho@google.com>
To: Paolo Bonzini <pbonzini@redhat.com>,
        Dan Williams <dan.j.williams@intel.com>,
        David Hildenbrand <david@redhat.com>,
        Dave Jiang <dave.jiang@intel.com>,
        Alexander Duyck <alexander.h.duyck@linux.intel.com>
Cc: linux-nvdimm@lists.01.org, x86@kernel.org, kvm@vger.kernel.org,
        linux-kernel@vger.kernel.org, yu.c.zhang@intel.com,
        yi.z.zhang@intel.com
Content-Type: text/plain; charset="UTF-8"
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

KVM has a use case for determining the size of a dax mapping.  The KVM
code has easy access to the address and the mm; hence the change in
parameters.

Signed-off-by: Barret Rhoden <brho@google.com>
Reviewed-by: David Hildenbrand <david@redhat.com>
Acked-by: Dan Williams <dan.j.williams@intel.com>
---
 include/linux/mm.h  |  3 +++
 mm/memory-failure.c | 38 +++-----------------------------------
 mm/util.c           | 34 ++++++++++++++++++++++++++++++++++
 3 files changed, 40 insertions(+), 35 deletions(-)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index fe52e266016e..c09e2f4c9bac 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -963,6 +963,9 @@ static inline bool is_pci_p2pdma_page(const struct page *page)
 }
 #endif /* CONFIG_DEV_PAGEMAP_OPS */
 
+unsigned long dev_pagemap_mapping_shift(unsigned long address,
+					struct mm_struct *mm);
+
 static inline void get_page(struct page *page)
 {
 	page = compound_head(page);
diff --git a/mm/memory-failure.c b/mm/memory-failure.c
index fc8b51744579..6779c163c4f4 100644
--- a/mm/memory-failure.c
+++ b/mm/memory-failure.c
@@ -265,40 +265,6 @@ void shake_page(struct page *p, int access)
 }
 EXPORT_SYMBOL_GPL(shake_page);
 
-static unsigned long dev_pagemap_mapping_shift(struct page *page,
-		struct vm_area_struct *vma)
-{
-	unsigned long address = vma_address(page, vma);
-	pgd_t *pgd;
-	p4d_t *p4d;
-	pud_t *pud;
-	pmd_t *pmd;
-	pte_t *pte;
-
-	pgd = pgd_offset(vma->vm_mm, address);
-	if (!pgd_present(*pgd))
-		return 0;
-	p4d = p4d_offset(pgd, address);
-	if (!p4d_present(*p4d))
-		return 0;
-	pud = pud_offset(p4d, address);
-	if (!pud_present(*pud))
-		return 0;
-	if (pud_devmap(*pud))
-		return PUD_SHIFT;
-	pmd = pmd_offset(pud, address);
-	if (!pmd_present(*pmd))
-		return 0;
-	if (pmd_devmap(*pmd))
-		return PMD_SHIFT;
-	pte = pte_offset_map(pmd, address);
-	if (!pte_present(*pte))
-		return 0;
-	if (pte_devmap(*pte))
-		return PAGE_SHIFT;
-	return 0;
-}
-
 /*
  * Failure handling: if we can't find or can't kill a process there's
  * not much we can do.	We just print a message and ignore otherwise.
@@ -329,7 +295,9 @@ static void add_to_kill(struct task_struct *tsk, struct page *p,
 	tk->addr = page_address_in_vma(p, vma);
 	tk->addr_valid = 1;
 	if (is_zone_device_page(p))
-		tk->size_shift = dev_pagemap_mapping_shift(p, vma);
+		tk->size_shift =
+			dev_pagemap_mapping_shift(vma_address(page, vma),
+						  vma->vm_mm);
 	else
 		tk->size_shift = compound_order(compound_head(p)) + PAGE_SHIFT;
 
diff --git a/mm/util.c b/mm/util.c
index f94a1ac09cd8..24444e35a7ed 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -795,3 +795,37 @@ int get_cmdline(struct task_struct *task, char *buffer, int buflen)
 out:
 	return res;
 }
+
+unsigned long dev_pagemap_mapping_shift(unsigned long address,
+					struct mm_struct *mm)
+{
+	pgd_t *pgd;
+	p4d_t *p4d;
+	pud_t *pud;
+	pmd_t *pmd;
+	pte_t *pte;
+
+	pgd = pgd_offset(mm, address);
+	if (!pgd_present(*pgd))
+		return 0;
+	p4d = p4d_offset(pgd, address);
+	if (!p4d_present(*p4d))
+		return 0;
+	pud = pud_offset(p4d, address);
+	if (!pud_present(*pud))
+		return 0;
+	if (pud_devmap(*pud))
+		return PUD_SHIFT;
+	pmd = pmd_offset(pud, address);
+	if (!pmd_present(*pmd))
+		return 0;
+	if (pmd_devmap(*pmd))
+		return PMD_SHIFT;
+	pte = pte_offset_map(pmd, address);
+	if (!pte_present(*pte))
+		return 0;
+	if (pte_devmap(*pte))
+		return PAGE_SHIFT;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dev_pagemap_mapping_shift);

From patchwork Thu Apr  4 20:23:44 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Barret Rhoden <brho@google.com>
X-Patchwork-Id: 10886267
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 986471708
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:15 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 86C1028AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:15 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7ADA128AF2; Thu,  4 Apr 2019 20:24:15 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-15.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI,
	USER_IN_DEF_DKIM_WL autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2060928AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:15 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730859AbfDDUYI (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 4 Apr 2019 16:24:08 -0400
Received: from mail-vk1-f202.google.com ([209.85.221.202]:43842 "EHLO
        mail-vk1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1730836AbfDDUYH (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 4 Apr 2019 16:24:07 -0400
Received: by mail-vk1-f202.google.com with SMTP id s11so1536353vkk.10
        for <kvm@vger.kernel.org>; Thu, 04 Apr 2019 13:24:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=0wnnkWPvsjcCmPpDGZZOltQ8m2/AePhqjWl4B6moFQY=;
        b=LyHguTLzka7Fymtke5wD0vAQz10+1dZFeGH0oVAdNqR7j1DOXQKKK0huAgxhaBkoB7
         I+mudDEJ3pbCi8PQYuaHvYRDIzdU4cB3pAIlB7eLp9sbX23LmYG652GWRUF+afV7Nbbn
         Rr4r0uDb23gG/8fG5xHPgzohfNXZs0S5Lm/pEkzeJEBCTJi6706yQTBUx+XWiWL91mGl
         iYPGcgOhit8eSqpfY/iGpBtuPaUwjZUdi0vD95kr7e/IVNa7jXejH9qipeHA6OkoWbVC
         D8naX3rQARsWVGJMkgNBWeGIRK1BTA4JJU1PbP/4YD2Sqfz2e7hVkpAG/3mIHbmWln6U
         5FxA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=0wnnkWPvsjcCmPpDGZZOltQ8m2/AePhqjWl4B6moFQY=;
        b=t2SrGta64rA5VA3x5r9Uov2MWIHLAMFMR7qnDHqfib7wpDye6ZlQkoDO2393vyBthQ
         g01PKjDKJ75L4ITWhoxBCZ7vNNiSE5e09HJXfAq7Cb+2e1hd0GLQE/5y67VDZ3gAdKVC
         MJbZbgek5y+pKwNe3gC6IMWvPy/C2xG2D2vWjIGCvJmnZ0dMHJowu7Nt0FAjPi1hltl+
         O3BrYjdinaLBC7y9l8SQoA5b551c6CJA8CnQTK88gitVBCcIbcr8/Oy3LvXZapLIydni
         gZJFy778JeIkjo7m62no0minGRQJxkEhk9Mo75vvB7nXFn8XK7dxZYnCA7BIMBUsj5xN
         OnAg==
X-Gm-Message-State: APjAAAV0ZRPylhwo4m6W9ZJcJf2Zr9P/lGQk/WEwIIMBkHxUm6VeV2mt
        HpHG3lV2HGtoBuvwFd90OjbQ3SJA
X-Google-Smtp-Source: 
 APXvYqxfiNOMpTCx2nzD7rpIB+lfL/ESLm0Iwf/QdYpMzwDxx4q+nF/QwKtbz5yLo8mBd7eu7h8eVFZQ
X-Received: by 2002:a1f:9010:: with SMTP id s16mr1018825vkd.12.1554409445741;
 Thu, 04 Apr 2019 13:24:05 -0700 (PDT)
Date: Thu,  4 Apr 2019 16:23:44 -0400
In-Reply-To: <20190404202345.133553-1-brho@google.com>
Message-Id: <20190404202345.133553-3-brho@google.com>
Mime-Version: 1.0
References: <20190404202345.133553-1-brho@google.com>
X-Mailer: git-send-email 2.21.0.392.gf8f6787159e-goog
Subject: [PATCH v3 2/3] kvm: Use huge pages for DAX-backed files
From: Barret Rhoden <brho@google.com>
To: Paolo Bonzini <pbonzini@redhat.com>,
        Dan Williams <dan.j.williams@intel.com>,
        David Hildenbrand <david@redhat.com>,
        Dave Jiang <dave.jiang@intel.com>,
        Alexander Duyck <alexander.h.duyck@linux.intel.com>
Cc: linux-nvdimm@lists.01.org, x86@kernel.org, kvm@vger.kernel.org,
        linux-kernel@vger.kernel.org, yu.c.zhang@intel.com,
        yi.z.zhang@intel.com
Content-Type: text/plain; charset="UTF-8"
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

This change allows KVM to map DAX-backed files made of huge pages with
huge mappings in the EPT/TDP.

DAX pages are not PageTransCompound.  The existing check is trying to
determine if the mapping for the pfn is a huge mapping or not.  For
non-DAX maps, e.g. hugetlbfs, that means checking PageTransCompound.
For DAX, we can check the page table itself.

Note that KVM already faulted in the page (or huge page) in the host's
page table, and we hold the KVM mmu spinlock.  We grabbed that lock in
kvm_mmu_notifier_invalidate_range_end, before checking the mmu seq.

Signed-off-by: Barret Rhoden <brho@google.com>
---
 arch/x86/kvm/mmu.c | 33 +++++++++++++++++++++++++++++++--
 1 file changed, 31 insertions(+), 2 deletions(-)

diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index eee455a8a612..48cbf5553688 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -3207,6 +3207,35 @@ static int kvm_handle_bad_page(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn)
 	return -EFAULT;
 }
 
+static bool pfn_is_huge_mapped(struct kvm *kvm, gfn_t gfn, kvm_pfn_t pfn)
+{
+	struct page *page = pfn_to_page(pfn);
+	unsigned long hva;
+
+	if (!is_zone_device_page(page))
+		return PageTransCompoundMap(page);
+
+	/*
+	 * DAX pages do not use compound pages.  The page should have already
+	 * been mapped into the host-side page table during try_async_pf(), so
+	 * we can check the page tables directly.
+	 */
+	hva = gfn_to_hva(kvm, gfn);
+	if (kvm_is_error_hva(hva))
+		return false;
+
+	/*
+	 * Our caller grabbed the KVM mmu_lock with a successful
+	 * mmu_notifier_retry, so we're safe to walk the page table.
+	 */
+	switch (dev_pagemap_mapping_shift(hva, current->mm)) {
+	case PMD_SHIFT:
+	case PUD_SIZE:
+		return true;
+	}
+	return false;
+}
+
 static void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,
 					gfn_t *gfnp, kvm_pfn_t *pfnp,
 					int *levelp)
@@ -3223,7 +3252,7 @@ static void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,
 	 */
 	if (!is_error_noslot_pfn(pfn) && !kvm_is_reserved_pfn(pfn) &&
 	    level == PT_PAGE_TABLE_LEVEL &&
-	    PageTransCompoundMap(pfn_to_page(pfn)) &&
+	    pfn_is_huge_mapped(vcpu->kvm, gfn, pfn) &&
 	    !mmu_gfn_lpage_is_disallowed(vcpu, gfn, PT_DIRECTORY_LEVEL)) {
 		unsigned long mask;
 		/*
@@ -5774,7 +5803,7 @@ static bool kvm_mmu_zap_collapsible_spte(struct kvm *kvm,
 		 */
 		if (sp->role.direct &&
 			!kvm_is_reserved_pfn(pfn) &&
-			PageTransCompoundMap(pfn_to_page(pfn))) {
+			pfn_is_huge_mapped(kvm, sp->gfn, pfn)) {
 			pte_list_remove(rmap_head, sptep);
 
 			if (kvm_available_flush_tlb_with_range())

From patchwork Thu Apr  4 20:23:45 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Barret Rhoden <brho@google.com>
X-Patchwork-Id: 10886269
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 1AC9E922
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:18 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 07CC928AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:18 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id F003128AF2; Thu,  4 Apr 2019 20:24:17 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-15.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI,
	USER_IN_DEF_DKIM_WL autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9A2F228AE3
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  4 Apr 2019 20:24:17 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730855AbfDDUYQ (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 4 Apr 2019 16:24:16 -0400
Received: from mail-qk1-f202.google.com ([209.85.222.202]:36644 "EHLO
        mail-qk1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1730848AbfDDUYI (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 4 Apr 2019 16:24:08 -0400
Received: by mail-qk1-f202.google.com with SMTP id y64so3221364qka.3
        for <kvm@vger.kernel.org>; Thu, 04 Apr 2019 13:24:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=xCLL7LcnK/EfAdZPNNEYIgclrtC6A/GQfyjKs9KqXfk=;
        b=R6urs1OnBmpgDtETpgp5lhwN1bbIvjyh0T0PxRNx8AMkjoOKTYS9L6pfHJyaINvgN7
         6b/xo1AdfuHQtR/rADaYjHn9OD+lUYOKAjswnTZk1i9hmpJZmN85/ye6cFy847HPXBxV
         KIw+51PUdGPSAn1SfUVM8fOpwqx1xk9zRzuv8ifLhbp4jrRVYgPQrmV9yeDdBehA9UYC
         UoV5bJn1NAF3i7HknTXqzXSXjATIV+iVOKdzFGZyHbJ1BIXZJJeGa5RBrtpecLdXwSjo
         17lzlrVHY0ubvY9k6NzTm/HPm5ua31iKV43twrPTLhHdyuBXjn1gycxqgcA6kEMROM63
         w4fg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=xCLL7LcnK/EfAdZPNNEYIgclrtC6A/GQfyjKs9KqXfk=;
        b=lV13YNtOBnbOtJQl4POY5RkYPTabeH1Qa2FWA0RgVbMcbXEkeMXEmr8jBDd+r/ozQO
         Oc74d0QNrzYCoj3keUjHoZYULSL4qg5cIKZfo8dszAt1Veh1MAIbslnzoy2QKObJkamN
         XnW9Y77d+M4redWFCNO6Vhog2vl0jf1o8wHPKdEQC/mbM9WMLcZGHB2nWQmlyShaBetL
         TXC+qg9CZkYmDBosvu3RReZGV56tq+BSqHnto6vVKpKQ6p4FlA/GQuavnZ0LOouoVMmD
         /XXFswxcXSH3nh1H7SmHa7heBUplBqP777qrr7BBY1whL3w74EGHfRZw5sSy//vNbh5M
         FNLQ==
X-Gm-Message-State: APjAAAVMHpOwRbLWfKkx6oG5rfpfqD4F8/QbJ5d/3WX3fM9HSNv5fGYp
        4giqyDHGrIRNIg+ZAMXy0zseZa+P
X-Google-Smtp-Source: 
 APXvYqznMxtqI38l39KsNnxVYhuotW8fBQzlZRNiusEEq702paDjnOTBVACaULock+UYMm0yj6YtKIA1
X-Received: by 2002:ac8:24d2:: with SMTP id t18mr1266663qtt.1.1554409446885;
 Thu, 04 Apr 2019 13:24:06 -0700 (PDT)
Date: Thu,  4 Apr 2019 16:23:45 -0400
In-Reply-To: <20190404202345.133553-1-brho@google.com>
Message-Id: <20190404202345.133553-4-brho@google.com>
Mime-Version: 1.0
References: <20190404202345.133553-1-brho@google.com>
X-Mailer: git-send-email 2.21.0.392.gf8f6787159e-goog
Subject: [PATCH v3 3/3] kvm: remove redundant PageReserved() check
From: Barret Rhoden <brho@google.com>
To: Paolo Bonzini <pbonzini@redhat.com>,
        Dan Williams <dan.j.williams@intel.com>,
        David Hildenbrand <david@redhat.com>,
        Dave Jiang <dave.jiang@intel.com>,
        Alexander Duyck <alexander.h.duyck@linux.intel.com>
Cc: linux-nvdimm@lists.01.org, x86@kernel.org, kvm@vger.kernel.org,
        linux-kernel@vger.kernel.org, yu.c.zhang@intel.com,
        yi.z.zhang@intel.com
Content-Type: text/plain; charset="UTF-8"
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

kvm_is_reserved_pfn() already checks PageReserved().

Signed-off-by: Barret Rhoden <brho@google.com>
Reviewed-by: David Hildenbrand <david@redhat.com>
---
 virt/kvm/kvm_main.c | 8 ++------
 1 file changed, 2 insertions(+), 6 deletions(-)

diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 55fe8e20d8fd..c44985375e7f 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -1782,12 +1782,8 @@ EXPORT_SYMBOL_GPL(kvm_release_pfn_dirty);
 
 void kvm_set_pfn_dirty(kvm_pfn_t pfn)
 {
-	if (!kvm_is_reserved_pfn(pfn)) {
-		struct page *page = pfn_to_page(pfn);
-
-		if (!PageReserved(page))
-			SetPageDirty(page);
-	}
+	if (!kvm_is_reserved_pfn(pfn))
+		SetPageDirty(pfn_to_page(pfn));
 }
 EXPORT_SYMBOL_GPL(kvm_set_pfn_dirty);
 
